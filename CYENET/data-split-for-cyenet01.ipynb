{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Set Environment","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport cv2\nimport random\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport pickle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set Seed for Reproducibility","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=21019):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    #os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking if shapes are consistent","metadata":{}},{"cell_type":"code","source":"train_dir = ['/kaggle/input/intel-mobileodt-cervical-cancer-screening/train/train/Type_1',\n             '/kaggle/input/intel-mobileodt-cervical-cancer-screening/train/train/Type_2',\n             '/kaggle/input/intel-mobileodt-cervical-cancer-screening/train/train/Type_3',\n             '/kaggle/input/intel-mobileodt-cervical-cancer-screening/additional_Type_1_v2/Type_1',\n             '/kaggle/input/intel-mobileodt-cervical-cancer-screening/additional_Type_2_v2/Type_2',\n             '/kaggle/input/intel-mobileodt-cervical-cancer-screening/additional_Type_3_v2/Type_3']\n\ndf = pd.DataFrame(columns = ['train_dir', 'no_samples', 'random_sample', 'image_shape'])\nfor path in train_dir:\n    files = os.listdir(path)\n    no_samples = len(files)\n    random_file = random.choice(files)\n    image = cv2.imread(os.path.join(path,random_file))\n    image_shape = image.shape\n    df = df.append({'train_dir':path,\n                    'no_samples':no_samples,\n                    'random_sample':random_file,\n                    'image_shape':image_shape},\n                   ignore_index = True)\n    \ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Image shape is inconsistent; needs to be reshaped**","metadata":{}},{"cell_type":"markdown","source":"# See Random Samples","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18,15))\nfor i in range(len(df)):\n    image = cv2.imread(os.path.join(df['train_dir'][i],df['random_sample'][i]))\n    plt.subplot(2, 3, i+1)\n    plt.imshow(image)\n    \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Dataset","metadata":{}},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\njpg = '*.jpg'\ntype1 = glob.glob(os.path.join(df['train_dir'][0],jpg))\ntype2 = glob.glob(os.path.join(df['train_dir'][1],jpg))\ntype3 = glob.glob(os.path.join(df['train_dir'][2],jpg))\nv2_type1 = glob.glob(os.path.join(df['train_dir'][3],jpg))\nv2_type2 = glob.glob(os.path.join(df['train_dir'][4],jpg))\nv2_type3 = glob.glob(os.path.join(df['train_dir'][5],jpg))\n\ndata = []\nlabels = []\nclass_names = list(['Type 1','Type 2','Type 3'])\nimage_size = (227, 227)\n\nfor i in type1:   \n    image = cv2.imread(i)\n    try:\n        image = cv2.resize(image, image_size, interpolation=cv2.INTER_AREA)\n    except:\n        break\n    data.append(image)\n    labels.append(0)\n    \nfor i in type2:   \n    image = cv2.imread(i)\n    try:\n        image = cv2.resize(image, image_size, interpolation=cv2.INTER_AREA)\n    except:\n        break\n    data.append(image)\n    labels.append(1)\n    \nfor i in type3:   \n    image = cv2.imread(i)\n    try:\n        image = cv2.resize(image, image_size, interpolation=cv2.INTER_AREA)\n    except:\n        break\n    data.append(image)\n    labels.append(2)\n\nfor i in v2_type1:   \n    image = cv2.imread(i)\n    try:\n        image = cv2.resize(image, image_size, interpolation=cv2.INTER_AREA)\n    except:\n        break\n    data.append(image)\n    labels.append(0)\n    \nfor i in v2_type2:   \n    image = cv2.imread(i)\n    try:\n        image = cv2.resize(image, image_size, interpolation=cv2.INTER_AREA)\n    except:\n        break\n    data.append(image)\n    labels.append(1)\n    \nfor i in v2_type3:   \n    image = cv2.imread(i)\n    try:\n        image = cv2.resize(image, image_size, interpolation=cv2.INTER_AREA)\n    except:\n        break\n    data.append(image)\n    labels.append(2)\n    \nX = np.array(data)\ny = np.array(labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for consistency in data and label shapes and file counts\nprint(f'Dataset Shape: {X.shape}, Labels Shape: {y.shape}')\nprint(f'Type 1 Samples: {np.count_nonzero(y==0)}')\nprint(f'Type 2 Samples: {np.count_nonzero(y==1)}')\nprint(f'Type 3 Samples: {np.count_nonzero(y==2)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Validation-Test Split","metadata":{}},{"cell_type":"code","source":"# Perform train-test split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n\n# Perform train-validation split\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=19)\n# Change random_state value for a different split\n\nprint(f'Samples in Train Set: {len(y_train)}')\nprint(f'Samples in Validation Set: {len(y_val)}')\nprint(f'Samples in Test Set: {len(y_test)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save split sets for reproduction","metadata":{}},{"cell_type":"code","source":"splits = {\n    'x_train': x_train,\n    'x_val': x_val,\n    'x_test': x_test,\n    'y_train': y_train,\n    'y_val': y_val,\n    'y_test': y_test\n}\n\nwith open('data_splits_for_cyenet.pkl', 'wb') as f:\n    pickle.dump(splits, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Code for loading data in your notebook from the saved pickle file","metadata":{}},{"cell_type":"code","source":"with open('data_splits_for_cyenet.pkl', 'rb') as f:\n    loaded_splits = pickle.load(f)\n\nx_train = loaded_splits['x_train']\nx_val = loaded_splits['x_val']\nx_test = loaded_splits['x_test']\ny_train = loaded_splits['y_train']\ny_val = loaded_splits['y_val']\ny_test = loaded_splits['y_test']","metadata":{},"execution_count":null,"outputs":[]}]}